// src/composables/useVoiceAssistant.js
import { ref, onUnmounted } from 'vue';
import { correctTranscript, extractBatchPlates } from '../utils/textUtils';

export function useVoiceAssistant() {
  const isVoiceListening = ref(false); // ç¸½é–‹é—œ
  const isListening = ref(false);      // å¯¦éš›éº¥å…‹é¢¨ç‹€æ…‹
  const isSystemSpeaking = ref(false); // ç³»çµ±æ­£åœ¨èªªè©±
  const message = ref('');             // èªéŸ³ç›¸é—œè¨Šæ¯
  
  // å…§éƒ¨è®Šæ•¸
  let recognition = null;
  let voiceBuffer = "";
  let bufferTimer = null;
  let wakeLock = null;
  const audioPlayer = new Audio();
  const Recognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  // ==========================================
  // ã€æ–°å¢ã€‘å¼·åˆ¶å–šé†’è—ç‰™éº¥å…‹é¢¨çš„å‡½å¼
  // ==========================================
  // ==========================================
  // ã€åŠ å¼·ç‰ˆã€‘ç²¾æº–é–å®šè—ç‰™è£ç½®ä¸¦å–šé†’
  // ==========================================
  const wakeUpBluetooth = async () => {
    try {
      message.value = "æ­£åœ¨æœå°‹è—ç‰™è€³æ©Ÿ...";
      
      // 1. ç¬¬ä¸€æ¬¡è«‹æ±‚ï¼šç‚ºäº†æ‹¿æ¬Šé™ (ä¸ç„¶ enumerateDevices æ¨™ç±¤æœƒæ˜¯ç©ºçš„)
      // é€™ä¸€é»é»æ™‚é–“é †ä¾¿è®“ Android çŸ¥é“æˆ‘å€‘è¦ç”¨éº¥å…‹é¢¨
      let stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      stream.getTracks().forEach(track => track.stop()); // ç”¨å®Œé¦¬ä¸Šé—œï¼Œæº–å‚™ä¸‹ä¸€æ­¥

      // 2. åˆ—å‡ºæ‰€æœ‰è£ç½®ï¼Œæ‰¾å‡ºé‚£æ˜¯ã€Œç¬¬å¹¾å€‹ã€
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter(device => device.kind === 'audioinput');
      
      // --- ç­–ç•¥ Aï¼šæ™ºæ…§æœå°‹ (æ¨è–¦) ---
      // æ‰¾åå­—è£¡é¢æœ‰ "Bluetooth", "Headset", "JLab" (æ‚¨çš„è€³æ©Ÿç‰Œå­) çš„
      let targetDevice = audioInputs.find(d => 
      // d.label.toLowerCase().includes('headset') ||
        d.label.toLowerCase().includes('jlab') ||
        d.label.toLowerCase().includes('bluetooth')
      );
      // --- ç­–ç•¥ Bï¼šå¦‚æœæ‚¨å¾ˆç¢ºå®šå®ƒæ˜¯ã€Œæœ€å¾Œä¸€å€‹ã€(é€šå¸¸è—ç‰™æ˜¯æœ€å¾ŒåŠ å…¥çš„) ---
      // å¦‚æœç­–ç•¥ A æ²’æ‰¾åˆ°ï¼Œå°±é è¨­æŠ“æ¸…å–®è£¡æœ€å¾Œä¸€å€‹
      if (!targetDevice && audioInputs.length > 1) {
        targetDevice = audioInputs[audioInputs.length - 1];
      }
      if (targetDevice) {
        message.value = `é–å®šè£ç½®: ${targetDevice.label || 'å¤–æ¥/è—ç‰™è£ç½®'}`;
        console.log("é–å®šç›®æ¨™ ID:", targetDevice.deviceId);

        // 3. ã€é—œéµæ­¥é©Ÿã€‘æŒ‡å®š deviceId å¼·åˆ¶é–‹å•Ÿ
        const bluetoothStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            deviceId: { exact: targetDevice.deviceId } // <--- é€™è£¡å°±æ˜¯åœ¨æŒ‡å®šã€Œç¬¬4å€‹ã€
          }
        });

        // 4. æˆåŠŸé€£ç·šå¾Œï¼Œç­‰å¾…ä¸€ç§’è®“ç³»çµ±åˆ‡æ›è·¯ç”±
        // é€™æ™‚å€™æ‚¨çš„è—ç‰™è€³æ©Ÿæ‡‰è©²æœƒè½åˆ°èƒŒæ™¯åº•å™ªæ”¹è®Š
        await new Promise(resolve => setTimeout(resolve, 1000));

        // 5. ä»»å‹™å®Œæˆï¼Œé‡‹æ”¾å®ƒï¼Œè®“ SpeechRecognition æ¥æ‰‹
        bluetoothStream.getTracks().forEach(track => track.stop());
        console.log("ğŸ¤ è—ç‰™é–å®šå–šé†’å®Œæˆ");
        
      } else {
        message.value = "æœªåµæ¸¬åˆ°è—ç‰™ç‰¹å¾µï¼Œä½¿ç”¨ç³»çµ±é è¨­";
        // æ²’æ‰¾åˆ°ç‰¹å®šè£ç½®ï¼Œå°±ç”¨é€šç”¨å–šé†’æ³• (é›–ç„¶ä¸å®Œç¾ä½†å ªç”¨)
        const defaultStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        defaultStream.getTracks().forEach(track => track.stop());
      }

    } catch (err) {
      console.error("è—ç‰™é–å®šå¤±æ•—:", err);
      message.value = "è—ç‰™é€£æ¥ç•°å¸¸ï¼Œåˆ‡æ›å›é è¨­";
    }
  };
  // è‡ªå®šç¾©å•å€™èª
  const greetings = ["å¤§å“¥è¾›è‹¦äº†ï¼Œè«‹èªªè»Šç‰Œ", "åƒé£½äº†å—ï¼Œç³»çµ±æº–å‚™å¥½äº†", "ç¾åœ¨å¯ä»¥é–‹å§‹æŸ¥è©¢è»Šç‰Œ"];

  // å¤–éƒ¨æ³¨å…¥çš„è™•ç†å‡½å¼ (ç•¶åˆ†æå‡ºè»Šç‰Œæ™‚å‘¼å«)
  let onPlatesDetected = null; 

  // --- 1. è¢å¹•é–å®š ---
  const requestWakeLock = async () => {
    try {
      if ('wakeLock' in navigator) {
        wakeLock = await navigator.wakeLock.request('screen');
        console.log('ğŸ’¡ è¢å¹•å–šé†’é–å®šå·²å•Ÿç”¨');
      }
    } catch (err) { console.error('è¢å¹•é–å®šå¤±æ•—', err); }
  };

  // --- 2. èªªè©±åŠŸèƒ½ (Speak) ---
  const speak = async (text, isResult = false) => {
    if (!text || text.trim() === "") return;
    isSystemSpeaking.value = true;

    // æš«åœè­˜åˆ¥ä»¥é˜²å›éŸ³
    if (recognition && isVoiceListening.value) {
      try { recognition.stop(); } catch (e) {}
    }

    const resumeListening = () => {
      setTimeout(() => {
        isSystemSpeaking.value = false;
        if (isVoiceListening.value && document.visibilityState === 'visible') {
          try { recognition.start(); } catch (e) {}
        }
      }, 500);
    };

    return new Promise((resolve) => {
      let textToSpeak = text;
      if (isResult) {
        textToSpeak = text.replace(/([a-zA-Z0-9])/g, '$1 ').replace(/-/g, ' ');
      }
      const utter = new SpeechSynthesisUtterance(textToSpeak);
      utter.lang = 'zh-TW';
      utter.rate = 0.9;
      utter.volume = 1;
      utter.onend = () => { resumeListening(); resolve(); };
      utter.onerror = () => { resumeListening(); resolve(); };
      
      window.speechSynthesis.cancel();
      window.speechSynthesis.speak(utter);
    });
  };

  // --- 3. æ ¸å¿ƒç›£è½é‚è¼¯ ---
  const handleVoiceResult = (event) => {
    if (isSystemSpeaking.value) return;

    let currentSegment = "";
    let isFinal = false;
    for (let i = event.resultIndex; i < event.results.length; i++) {
      if (event.results[i].isFinal) isFinal = true;
      currentSegment += event.results[i][0].transcript;
    }

    if (isFinal) {
      const correctedSegment = correctTranscript(currentSegment);
      voiceBuffer += correctedSegment;
      message.value = `è½å–ä¸­: ${voiceBuffer}`;

      if (voiceBuffer.includes('æŸ¥è©¢')) {
        const platesFound = extractBatchPlates(voiceBuffer);
        if (platesFound.length > 0) {
          const simulationInput = platesFound.join(' ');
          const totalLength = simulationInput.replace(/[-\s]/g, '').length;
          
          // å¿«é€Ÿé€šé—œé‚è¼¯
          if (totalLength >= 6) {
             triggerSearch(simulationInput, true);
             return;
          }

          // ç·©è¡é‚è¼¯
          if (bufferTimer) clearTimeout(bufferTimer);
          bufferTimer = setTimeout(() => {
             triggerSearch(simulationInput, false);
          }, 1200);
        }
      }
    }
  };
  
  const triggerSearch = (input, immediate) => {
      if (bufferTimer) clearTimeout(bufferTimer);
      console.log(`èªéŸ³è­˜åˆ¥çµæœ: ${input}`);
      
      // å‘¼å«å¤–éƒ¨æ³¨å…¥çš„è™•ç†å‡½å¼
      if (onPlatesDetected) onPlatesDetected(input);

      voiceBuffer = "";
  };

  // --- 4. å•Ÿå‹•/é—œé–‰é–‹é—œ ---
  const toggleVoiceSearch = async (callback) => {
    // è¨»å†Š callback
    if (callback) onPlatesDetected = callback;

    if (!Recognition) return alert("æ‚¨çš„ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³åŠŸèƒ½");

    // éŸ³è¨Šé ç†±
    audioPlayer.src = "data:audio/wav;base64,UklGRiQAAABXQVZFRm10IBAAAAABAAEAgD8AAIA/AAABAAgAZGF0YQAAAAA=";
    audioPlayer.play().catch(() => {});

    await requestWakeLock();

    // é—œé–‰é‚è¼¯
    if (isVoiceListening.value) {
      isVoiceListening.value = false;
      isSystemSpeaking.value = false;
      if (recognition) recognition.stop();
      if (bufferTimer) clearTimeout(bufferTimer);
      voiceBuffer = "";
      message.value = "èªéŸ³ç›£è½å·²é—œé–‰";
      return;
    }

    // å•Ÿå‹•é‚è¼¯
    isVoiceListening.value = true;
    const welcome = greetings[Math.floor(Math.random() * greetings.length)];
    message.value = `ç³»çµ±å•Ÿå‹•ï¼š${welcome}`;
    await speak(welcome);

    if (!recognition) {
      recognition = new Recognition();
      recognition.lang = 'zh-TW';
      recognition.continuous = true;
      recognition.interimResults = true;
      
      recognition.onstart = () => { isListening.value = true; message.value = "ğŸ¤ ç›£è½ä¸­..."; };
      recognition.onend = () => {
         isListening.value = false;
         // è‡ªå‹•é‡å•Ÿæ©Ÿåˆ¶
         if (document.visibilityState === 'visible' && isVoiceListening.value && !isSystemSpeaking.value) {
             try { recognition.start(); } catch(e) {}
         }
      };
      recognition.onerror = (e) => {
          console.error("èªéŸ³éŒ¯èª¤", e.error);
          if (e.error === 'not-allowed') {
             isVoiceListening.value = false;
             isListening.value = false;
          }
      };
      recognition.onresult = handleVoiceResult;
    }

    try { recognition.start(); } catch(e) {}
  };

  // --- 5. é é¢å¯è¦‹æ€§è™•ç† (æ ¸å½ˆç´šé‡é€£) ---
  const handleVisibilityChange = async () => {
    if (document.visibilityState === 'visible') {
      await requestWakeLock();
      if (isVoiceListening.value) {
        message.value = "ç³»çµ±å–šé†’ä¸­...";
        if (recognition) recognition.abort();
        setTimeout(() => {
           if (recognition && isVoiceListening.value) recognition.start().catch(()=>{});
        }, 500);
      }
    }
  };

  // ç”Ÿå‘½é€±æœŸæ¸…ç†
  onUnmounted(() => {
     if (wakeLock) wakeLock.release();
     if (recognition) recognition.abort();
     document.removeEventListener('visibilitychange', handleVisibilityChange);
  });

  // è¨»å†Šå…¨åŸŸç›£è½
  document.addEventListener('visibilitychange', handleVisibilityChange);

  return {
    isVoiceListening,
    isListening,
    message, // è®“å¤–å±¤å¯ä»¥é¡¯ç¤ºèªéŸ³ç‹€æ…‹
    toggleVoiceSearch,
    speak // åŒ¯å‡º speak è®“æœå°‹åŠŸèƒ½å¯ä»¥ç”¨
  };
}